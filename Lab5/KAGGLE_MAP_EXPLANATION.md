# Kaggle mAP è©•ä¼°è…³æœ¬è©³ç´°åˆ†æ

## ğŸ“‹ æ–‡ä»¶æ¦‚è¿°

**æ–‡ä»¶è·¯å¾‘ï¼š** `Lab5/kaggle_map.py`

**ç”¨é€”ï¼š** Kaggleç«¶è³½çš„ç‰©é«”æª¢æ¸¬è©•ä¼°æŒ‡æ¨™è¨ˆç®—è…³æœ¬ï¼Œå¯¦ç¾ **VOC-style mAP @ IoU 0.5**

**ä¸»è¦åŠŸèƒ½ï¼š**
1. è§£æCSVæ ¼å¼çš„é æ¸¬çµæœå’ŒçœŸå¯¦æ¨™ç±¤
2. è¨ˆç®—æ¯å€‹é¡åˆ¥çš„Average Precision (AP)
3. è¿”å›æ‰€æœ‰é¡åˆ¥çš„å¹³å‡å€¼ (mean AP)

---

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

### mAP (mean Average Precision)

```
mAP = (1/20) Ã— Î£ AP_i
```

å…¶ä¸­ï¼š
- 20å€‹é¡åˆ¥ï¼šPASCAL VOCæ•¸æ“šé›†çš„20å€‹ç‰©é«”é¡åˆ¥
- AP_iï¼šç¬¬iå€‹é¡åˆ¥çš„Average Precision

### IoUé–¾å€¼

```python
IOU_THRESHOLD: float = 0.5
```

- **IoU â‰¥ 0.5**ï¼šé æ¸¬æ¡†è¦–ç‚ºæ­£ç¢º (True Positive)
- **IoU < 0.5**ï¼šé æ¸¬æ¡†è¦–ç‚ºéŒ¯èª¤ (False Positive)

---

## ğŸ“Š æ•¸æ“šæ ¼å¼

### CSVæ–‡ä»¶çµæ§‹

**Solution (çœŸå¯¦æ¨™ç±¤)ï¼š**
```csv
id,prediction_list
2007_000027,"[['person', 1.0, 174, 101, 349, 351], ['chair', 1.0, 6, 112, 362, 450]]"
```

**Submission (é æ¸¬çµæœ)ï¼š**
```csv
id,prediction_list
2007_000027,"[['person', 0.95, 170, 98, 352, 348], ['chair', 0.87, 5, 110, 365, 455]]"
```

### é æ¸¬åˆ—è¡¨æ ¼å¼

æ¯å€‹æª¢æ¸¬æ¡†ç·¨ç¢¼ç‚ºï¼š
```python
['class_name', score, xmin, ymin, xmax, ymax]
```

**æ¬„ä½èªªæ˜ï¼š**
- `class_name` (str)ï¼šç‰©é«”é¡åˆ¥åç¨±ï¼ˆå¦‚ "person"ï¼‰
- `score` (float)ï¼šç½®ä¿¡åº¦åˆ†æ•¸ï¼ˆ0.0 ~ 1.0ï¼‰
- `xmin, ymin` (float)ï¼šå·¦ä¸Šè§’åæ¨™
- `xmax, ymax` (float)ï¼šå³ä¸‹è§’åæ¨™

**ç¤ºä¾‹ï¼š**
```python
['person', 0.95, 174.5, 101.3, 349.2, 351.8]
# å«ç¾©ï¼šæª¢æ¸¬åˆ°ä¸€å€‹"person"ï¼Œç½®ä¿¡åº¦0.95ï¼Œä½æ–¼(174.5, 101.3)åˆ°(349.2, 351.8)
```

---

## ğŸ”§ ä¸»è¦å‡½æ•¸åˆ†æ

### 1. `score()` - ä¸»è©•ä¼°å‡½æ•¸

**å‡½æ•¸ç°½åï¼š**
```python
def score(solution: pd.DataFrame, 
         submission: pd.DataFrame, 
         row_id_column_name: str) -> float
```

**åŠŸèƒ½ï¼š** è¨ˆç®—submissionç›¸å°æ–¼solutionçš„mAPåˆ†æ•¸

**è™•ç†æµç¨‹ï¼š**

#### Step 1: é©—è­‰æ•¸æ“šå®Œæ•´æ€§
```python
_validate_columns(solution, submission, row_id_column_name)
```
- æª¢æŸ¥å¿…è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
- æª¢æŸ¥æ˜¯å¦æœ‰é‡è¤‡çš„image_id
- æª¢æŸ¥submissionæ˜¯å¦åŒ…å«æ‰€æœ‰å¿…éœ€çš„image_id

#### Step 2: è§£æçœŸå¯¦æ¨™ç±¤
```python
gt_boxes, gt_class_counts = _parse_ground_truth(sol["prediction_list"])
```
- è§£ææ¯å¼µåœ–ç‰‡çš„çœŸå¯¦æ¡†
- çµ±è¨ˆæ¯å€‹é¡åˆ¥çš„çœŸå¯¦æ¡†æ•¸é‡

#### Step 3: è§£æé æ¸¬çµæœ
```python
pred_by_class = _parse_predictions(sub["prediction_list"])
```
- å°‡é æ¸¬çµæœæŒ‰é¡åˆ¥åˆ†çµ„
- ä¿ç•™image_idå’Œconfidenceä¿¡æ¯

#### Step 4: è¨ˆç®—æ¯å€‹é¡åˆ¥çš„AP
```python
for class_idx in range(len(CLASSES)):
    ap = _average_precision_for_class(
        class_idx,
        gt_boxes,
        gt_class_counts[class_idx],
        pred_by_class[class_idx],
    )
    if ap is not None:
        aps.append(ap)
```

#### Step 5: è¿”å›mAP
```python
result = float(np.mean(aps))
```

**è¿”å›å€¼ï¼š**
- `float`ï¼šmAPåˆ†æ•¸ï¼ˆ0.0 ~ 1.0ï¼‰
- å¦‚æœçµæœéæœ‰é™å€¼ï¼ˆNaN/Infï¼‰ï¼Œè¿”å›0.0

---

### 2. `_parse_ground_truth()` - è§£æçœŸå¯¦æ¨™ç±¤

**å‡½æ•¸ç°½åï¼š**
```python
def _parse_ground_truth(series: pd.Series) -> Tuple[Dict, np.ndarray]
```

**åŠŸèƒ½ï¼š** å°‡CSVä¸­çš„å­—ç¬¦ä¸²è½‰æ›ç‚ºå¯æŸ¥è©¢çš„æ•¸æ“šçµæ§‹

**è¿”å›å€¼ï¼š**

#### a) `gt_boxes: Dict[Tuple[str, int], List[np.ndarray]]`

**çµæ§‹ï¼š**
```python
{
    ('2007_000027', 14): [array([174., 101., 349., 351.])],  # person
    ('2007_000027', 8):  [array([6., 112., 362., 450.])]      # chair
}
```

**éµ (key)ï¼š** `(image_id, class_idx)`
**å€¼ (value)ï¼š** è©²åœ–ç‰‡ä¸­è©²é¡åˆ¥çš„æ‰€æœ‰çœŸå¯¦æ¡†åˆ—è¡¨

#### b) `class_counts: np.ndarray`

**çµæ§‹ï¼š**
```python
array([120, 85, 95, ...])  # 20å€‹å…ƒç´ ï¼Œæ¯å€‹æ˜¯è©²é¡åˆ¥çš„ç¸½æ¡†æ•¸
```

**ç”¨é€”ï¼š** è¨ˆç®—Recallæ™‚éœ€è¦çŸ¥é“ç¸½å…±æœ‰å¤šå°‘å€‹çœŸå¯¦æ¡†

---

### 3. `_parse_predictions()` - è§£æé æ¸¬çµæœ

**å‡½æ•¸ç°½åï¼š**
```python
def _parse_predictions(series: pd.Series) -> Dict[int, List[Tuple]]
```

**åŠŸèƒ½ï¼š** å°‡é æ¸¬çµæœæŒ‰é¡åˆ¥åˆ†çµ„

**è¿”å›å€¼ï¼š**

```python
{
    14: [  # class_idx=14 (person)
        ('2007_000027', 0.95, array([170., 98., 352., 348.])),
        ('2007_000032', 0.87, array([...]))
    ],
    8: [   # class_idx=8 (chair)
        ('2007_000027', 0.87, array([5., 110., 365., 455.])),
        ...
    ]
}
```

**æ ¼å¼ï¼š** `{class_idx: [(image_id, score, box), ...]}`

**ç‰¹é»ï¼š**
- æ‰€æœ‰é æ¸¬éƒ½æŒ‰é¡åˆ¥åˆ†çµ„
- ä¿ç•™åŸå§‹é †åºï¼ˆç¨å¾ŒæœƒæŒ‰scoreæ’åºï¼‰
- é©—è­‰confidenceåœ¨[0, 1]ç¯„åœå…§

---

### 4. `_decode_prediction_list()` - è§£ç¢¼å–®å€‹é æ¸¬åˆ—è¡¨

**å‡½æ•¸ç°½åï¼š**
```python
def _decode_prediction_list(value: object, 
                           *, 
                           context: str) -> List[Tuple]
```

**åŠŸèƒ½ï¼š** å°‡å­—ç¬¦ä¸²è½‰æ›ç‚ºPythonå°è±¡

**è™•ç†æµç¨‹ï¼š**

#### Step 1: è™•ç†ç©ºå€¼
```python
if value is None or (isinstance(value, float) and np.isnan(value)):
    return []
```

#### Step 2: è§£æå­—ç¬¦ä¸²
```python
data = ast.literal_eval(stripped)
```
- ä½¿ç”¨`ast.literal_eval()`å®‰å…¨åœ°è§£æPythonå­—é¢é‡
- æ¯”`eval()`å®‰å…¨ï¼ˆä¸åŸ·è¡Œä»»æ„ä»£ç¢¼ï¼‰

#### Step 3: é©—è­‰æ ¼å¼
```python
if len(det) != 6:
    raise ParticipantVisibleError(...)
```
- æ¯å€‹æª¢æ¸¬å¿…é ˆæœ‰6å€‹å…ƒç´ 
- `[class_name, score, xmin, ymin, xmax, ymax]`

#### Step 4: é©—è­‰é¡åˆ¥åç¨±
```python
if class_name not in CLASS_TO_INDEX:
    raise ParticipantVisibleError(f"Unknown class '{class_name}'.")
```

#### Step 5: é©—è­‰é‚Šç•Œæ¡†
```python
if xmax_f < xmin_f or ymax_f < ymin_f:
    raise ParticipantVisibleError("Bounding box has negative area.")
```

**è¿”å›å€¼ï¼š**
```python
[(class_idx, score, box), ...]
```

---

### 5. `_average_precision_for_class()` - è¨ˆç®—å–®å€‹é¡åˆ¥çš„AP

**å‡½æ•¸ç°½åï¼š**
```python
def _average_precision_for_class(
    class_idx: int,
    gt_boxes: Dict,
    num_gt: int,
    predictions: Sequence[Tuple]
) -> Optional[float]
```

**åŠŸèƒ½ï¼š** å¯¦ç¾VOC2010 APè¨ˆç®—å”è­°

**è™•ç†æµç¨‹ï¼š**

#### Step 1: è™•ç†é‚Šç•Œæƒ…æ³
```python
if num_gt == 0:
    return None  # è©²é¡åˆ¥ç„¡çœŸå¯¦æ¡†ï¼Œä¸è¨ˆå…¥mAP
if not predictions:
    return 0.0   # ç„¡é æ¸¬ï¼ŒAP=0
```

#### Step 2: æŒ‰confidenceæ’åºé æ¸¬
```python
sorted_preds = sorted(predictions, key=lambda x: x[1], reverse=True)
```
- å¾é«˜åˆ°ä½æ’åº
- å„ªå…ˆè™•ç†ç½®ä¿¡åº¦é«˜çš„é æ¸¬

#### Step 3: åˆå§‹åŒ–TP/FPæ•¸çµ„
```python
tp = np.zeros(len(sorted_preds), dtype=np.float32)
fp = np.zeros(len(sorted_preds), dtype=np.float32)
```

#### Step 4: æ¨™è¨˜å·²åŒ¹é…çš„çœŸå¯¦æ¡†
```python
gt_used: Dict[Tuple[str, int], np.ndarray] = {
    key: np.zeros(len(boxes), dtype=bool) 
    for key, boxes in gt_boxes.items() if key[1] == class_idx
}
```
- æ¯å€‹çœŸå¯¦æ¡†åªèƒ½åŒ¹é…ä¸€æ¬¡ï¼ˆgreedy matchingï¼‰

#### Step 5: åŒ¹é…é æ¸¬èˆ‡çœŸå¯¦æ¡†
```python
for i, (image_id, score, box) in enumerate(sorted_preds):
    key = (image_id, class_idx)
    gts = gt_boxes.get(key, [])
    if gts:
        # è¨ˆç®—èˆ‡æ‰€æœ‰çœŸå¯¦æ¡†çš„IoU
        overlaps = np.array([_bbox_iou(box, gt_box) for gt_box in gts])
        best = overlaps.argmax()
        best_iou = overlaps[best]
        
        # åˆ¤æ–·æ˜¯å¦åŒ¹é…æˆåŠŸ
        if best_iou >= IOU_THRESHOLD and not gt_used[key][best]:
            tp[i] = 1.0  # True Positive
            gt_used[key][best] = True
        else:
            fp[i] = 1.0  # False Positive
    else:
        fp[i] = 1.0  # è©²åœ–ç‰‡ç„¡è©²é¡åˆ¥çœŸå¯¦æ¡†
```

**åŒ¹é…è¦å‰‡ï¼š**
1. æ‰¾åˆ°IoUæœ€å¤§çš„çœŸå¯¦æ¡†
2. IoU â‰¥ 0.5 ä¸”è©²çœŸå¯¦æ¡†æœªè¢«åŒ¹é… â†’ TP
3. å¦å‰‡ â†’ FP

#### Step 6: è¨ˆç®—ç´¯ç©TP/FP
```python
tp = np.cumsum(tp)
fp = np.cumsum(fp)
```

**ç¤ºä¾‹ï¼š**
```python
# åŸå§‹
tp = [1, 0, 1, 0, 1]
fp = [0, 1, 0, 1, 0]

# ç´¯ç©
tp = [1, 1, 2, 2, 3]  # åˆ°ç›®å‰ç‚ºæ­¢æœ‰å¤šå°‘TP
fp = [0, 1, 1, 2, 2]  # åˆ°ç›®å‰ç‚ºæ­¢æœ‰å¤šå°‘FP
```

#### Step 7: è¨ˆç®—Precisionå’ŒRecall
```python
recall = tp / num_gt
precision = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)
```

**å…¬å¼ï¼š**
```
Recall = TP / (TP + FN) = TP / num_gt
Precision = TP / (TP + FP)
```

**ç¤ºä¾‹ï¼š**
```python
num_gt = 5  # è©²é¡åˆ¥å…±5å€‹çœŸå¯¦æ¡†
tp = [1, 1, 2, 2, 3]
fp = [0, 1, 1, 2, 2]

recall    = [0.2, 0.2, 0.4, 0.4, 0.6]
precision = [1.0, 0.5, 0.67, 0.5, 0.6]
```

#### Step 8: è¨ˆç®—AP
```python
return _voc_ap(recall, precision)
```

---

### 6. `_bbox_iou()` - è¨ˆç®—IoU

**å‡½æ•¸ç°½åï¼š**
```python
def _bbox_iou(box_a: np.ndarray, box_b: np.ndarray) -> float
```

**åŠŸèƒ½ï¼š** è¨ˆç®—å…©å€‹é‚Šç•Œæ¡†çš„äº¤ä¸¦æ¯” (Intersection over Union)

**è¨ˆç®—æ­¥é©Ÿï¼š**

#### Step 1: è¨ˆç®—äº¤é›†å€åŸŸ
```python
ixmin = max(box_a[0], box_b[0])  # äº¤é›†å·¦é‚Šç•Œ
iymin = max(box_a[1], box_b[1])  # äº¤é›†ä¸Šé‚Šç•Œ
ixmax = min(box_a[2], box_b[2])  # äº¤é›†å³é‚Šç•Œ
iymax = min(box_a[3], box_b[3])  # äº¤é›†ä¸‹é‚Šç•Œ

iw = max(ixmax - ixmin + 1.0, 0.0)  # äº¤é›†å¯¬åº¦
ih = max(iymax - iymin + 1.0, 0.0)  # äº¤é›†é«˜åº¦
inter = iw * ih  # äº¤é›†é¢ç©
```

**ç‚ºä»€éº¼+1.0ï¼Ÿ**
- åƒç´ åæ¨™æ˜¯é›¢æ•£çš„
- å¦‚æœxmin=10, xmax=20ï¼Œå¯¦éš›æœ‰11å€‹åƒç´ ï¼ˆ10, 11, ..., 20ï¼‰
- å¯¬åº¦ = xmax - xmin + 1 = 11

#### Step 2: è¨ˆç®—å„æ¡†é¢ç©
```python
area_a = (box_a[2] - box_a[0] + 1.0) * (box_a[3] - box_a[1] + 1.0)
area_b = (box_b[2] - box_b[0] + 1.0) * (box_b[3] - box_b[1] + 1.0)
```

#### Step 3: è¨ˆç®—è¯é›†å’ŒIoU
```python
union = area_a + area_b - inter
if union <= 0.0:
    return 0.0
return float(inter / union)
```

**å…¬å¼ï¼š**
```
IoU = äº¤é›†é¢ç© / è¯é›†é¢ç©
    = inter / (area_a + area_b - inter)
```

**åœ–ç¤ºï¼š**
```
Box A: [10, 10, 50, 50]  (é¢ç© = 41Ã—41 = 1681)
Box B: [30, 30, 70, 70]  (é¢ç© = 41Ã—41 = 1681)

äº¤é›†: [30, 30, 50, 50]  (é¢ç© = 21Ã—21 = 441)
è¯é›†: 1681 + 1681 - 441 = 2921

IoU = 441 / 2921 â‰ˆ 0.15
```

---

### 7. `_voc_ap()` - VOC APè¨ˆç®—

**å‡½æ•¸ç°½åï¼š**
```python
def _voc_ap(recall: np.ndarray, precision: np.ndarray) -> float
```

**åŠŸèƒ½ï¼š** ä½¿ç”¨VOC2010å”è­°è¨ˆç®—APï¼ˆ11é»æ’å€¼æ³•çš„æ”¹é€²ç‰ˆï¼‰

**è™•ç†æ­¥é©Ÿï¼š**

#### Step 1: æ·»åŠ é‚Šç•Œé»
```python
mrec = np.concatenate(([0.0], recall, [1.0]))
mpre = np.concatenate(([0.0], precision, [0.0]))
```

**ç›®çš„ï¼š** ç¢ºä¿æ›²ç·šå¾(0,0)é–‹å§‹ï¼Œåˆ°(1,0)çµæŸ

#### Step 2: å–®èª¿åŒ–Precision
```python
for i in range(mpre.size - 1, 0, -1):
    mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])
```

**ä½œç”¨ï¼š** å°‡Precision-Recallæ›²ç·šè®Šç‚ºå–®èª¿éæ¸›

**ç¤ºä¾‹ï¼š**
```python
# åŸå§‹
precision = [1.0, 0.5, 0.67, 0.5, 0.6]

# å–®èª¿åŒ–ï¼ˆå¾å³å¾€å·¦å–æœ€å¤§å€¼ï¼‰
precision = [1.0, 0.67, 0.67, 0.6, 0.6]
```

**ç‚ºä»€éº¼é€™æ¨£åšï¼Ÿ**
- æ¶ˆé™¤é‹¸é½’ç‹€æ³¢å‹•
- ä½¿ç”¨"å³å´æœ€å¤§å€¼"ä½œç‚ºæ’å€¼
- VOC2010å”è­°è¦å®šçš„æ¨™æº–åšæ³•

#### Step 3: è¨ˆç®—æ›²ç·šä¸‹é¢ç©
```python
idx = np.where(mrec[1:] != mrec[:-1])[0]  # æ‰¾åˆ°Recallè®ŠåŒ–çš„ä½ç½®
ap = np.sum((mrec[idx + 1] - mrec[idx]) * mpre[idx + 1])
```

**å…¬å¼ï¼š**
```
AP = Î£ (Recall_{i+1} - Recall_i) Ã— Precision_{i+1}
```

**å¹¾ä½•æ„ç¾©ï¼š**
- è¨ˆç®—Precision-Recallæ›²ç·šä¸‹çš„é¢ç©
- ä½¿ç”¨çŸ©å½¢è¿‘ä¼¼ï¼ˆæ•¸å€¼ç©åˆ†ï¼‰

**åœ–ç¤ºï¼š**
```
Precision
    ^
1.0 |â–ˆ
    |â–ˆ
0.8 |â–ˆ   â–ˆ
    |â–ˆ   â–ˆ
0.6 |â–ˆ   â–ˆ   â–ˆ
    |â–ˆ   â–ˆ   â–ˆ
    +-----------> Recall
    0  0.2 0.4 0.6
    
AP = 1.0Ã—0.2 + 0.8Ã—0.2 + 0.6Ã—0.2 = 0.48
```

---

## ğŸ¯ å®Œæ•´è©•ä¼°æµç¨‹ç¤ºä¾‹

### è¼¸å…¥æ•¸æ“š

**Solution (çœŸå¯¦æ¨™ç±¤)ï¼š**
```csv
id,prediction_list
img1,"[['person', 1.0, 10, 10, 50, 50], ['car', 1.0, 60, 60, 100, 100]]"
img2,"[['person', 1.0, 20, 20, 60, 60]]"
```

**Submission (é æ¸¬çµæœ)ï¼š**
```csv
id,prediction_list
img1,"[['person', 0.9, 12, 12, 52, 52], ['car', 0.8, 62, 62, 102, 102], ['person', 0.7, 150, 150, 200, 200]]"
img2,"[['person', 0.95, 22, 22, 62, 62]]"
```

### è™•ç†æµç¨‹

#### 1. è§£æçœŸå¯¦æ¨™ç±¤
```python
gt_boxes = {
    ('img1', 14): [array([10, 10, 50, 50])],  # person
    ('img1', 6):  [array([60, 60, 100, 100])],  # car
    ('img2', 14): [array([20, 20, 60, 60])]   # person
}

class_counts = array([0, ..., 2, ..., 1, ...])  # personæœ‰2å€‹, caræœ‰1å€‹
```

#### 2. è§£æé æ¸¬çµæœ
```python
pred_by_class = {
    14: [  # person
        ('img1', 0.9, array([12, 12, 52, 52])),
        ('img2', 0.95, array([22, 22, 62, 62])),
        ('img1', 0.7, array([150, 150, 200, 200]))
    ],
    6: [  # car
        ('img1', 0.8, array([62, 62, 102, 102]))
    ]
}
```

#### 3. è¨ˆç®—personé¡åˆ¥çš„AP

**Step 3.1: æŒ‰confidenceæ’åº**
```python
sorted_preds = [
    ('img2', 0.95, array([22, 22, 62, 62])),  # æœ€é«˜confidence
    ('img1', 0.9, array([12, 12, 52, 52])),
    ('img1', 0.7, array([150, 150, 200, 200]))
]
```

**Step 3.2: åŒ¹é…é æ¸¬èˆ‡çœŸå¯¦æ¡†**

| é æ¸¬ | çœŸå¯¦æ¡† | IoU | åŒ¹é… | çµæœ |
|-----|--------|-----|------|-----|
| img2, conf=0.95, [22,22,62,62] | img2, [20,20,60,60] | 0.82 | âœ… | TP |
| img1, conf=0.9, [12,12,52,52] | img1, [10,10,50,50] | 0.84 | âœ… | TP |
| img1, conf=0.7, [150,150,200,200] | img1, [10,10,50,50] | 0.0 | âŒ | FP |

**Step 3.3: è¨ˆç®—TP/FP**
```python
tp = [1, 1, 0] â†’ cumsum â†’ [1, 2, 2]
fp = [0, 0, 1] â†’ cumsum â†’ [0, 0, 1]

num_gt = 2

recall    = [1/2, 2/2, 2/2] = [0.5, 1.0, 1.0]
precision = [1/1, 2/2, 2/3] = [1.0, 1.0, 0.67]
```

**Step 3.4: è¨ˆç®—AP**
```python
# æ·»åŠ é‚Šç•Œ
mrec = [0.0, 0.5, 1.0, 1.0, 1.0]
mpre = [0.0, 1.0, 1.0, 0.67, 0.0]

# å–®èª¿åŒ–
mpre = [0.0, 1.0, 1.0, 1.0, 0.0]

# è¨ˆç®—é¢ç©
AP_person = (0.5-0.0)Ã—1.0 + (1.0-0.5)Ã—1.0 + (1.0-1.0)Ã—1.0
         = 0.5 + 0.5 + 0.0
         = 1.0
```

#### 4. è¨ˆç®—caré¡åˆ¥çš„AP

**é¡ä¼¼æµç¨‹ï¼š**
```python
# åªæœ‰1å€‹é æ¸¬ï¼Œ1å€‹çœŸå¯¦æ¡†
# IoUè¨ˆç®—å¾ŒåŒ¹é…æˆåŠŸ
AP_car = 1.0
```

#### 5. è¨ˆç®—mAP
```python
mAP = (AP_person + AP_car) / 2
    = (1.0 + 1.0) / 2
    = 1.0
```

---

## âš ï¸ ç•°å¸¸è™•ç†

### ParticipantVisibleError

**å®šç¾©ï¼š**
```python
class ParticipantVisibleError(Exception):
    """Raised for submission issues that the competitor can fix."""
```

**ç”¨é€”ï¼š** å‘åƒè³½è€…é¡¯ç¤ºå¯ä»¥ä¿®å¾©çš„éŒ¯èª¤

### å¸¸è¦‹éŒ¯èª¤

#### 1. ç¼ºå°‘å¿…è¦æ¬„ä½
```python
ParticipantVisibleError("Submission file missing columns: ['prediction_list']")
```

#### 2. é‡è¤‡çš„image_id
```python
ParticipantVisibleError("Submission contains duplicated image ids.")
```

#### 3. ç¼ºå°‘é æ¸¬
```python
ParticipantVisibleError("Submission is missing predictions for ids: ['img1', 'img2']")
```

#### 4. æœªçŸ¥é¡åˆ¥
```python
ParticipantVisibleError("Unknown class 'dog'.")
```

#### 5. éæ³•confidence
```python
ParticipantVisibleError("Invalid confidence score -0.5 for image img1.")
```

#### 6. è² é¢ç©é‚Šç•Œæ¡†
```python
ParticipantVisibleError("Bounding box has negative area.")
```

---

## ğŸ“ èˆ‡ predict_test.py çš„é—œè¯

### predict_test.py ç”Ÿæˆçš„æ ¼å¼

```python
# predict_test.py è¼¸å‡º
result = {
    'image_id': ['2007_000027', '2007_000032', ...],
    'label_list': [
        '14 0.315 0.229 0.445 0.478 0.972',  # class_id x1 y1 x2 y2 conf
        '11 0.156 0.129 0.712 0.893 0.965',
        ...
    ]
}
```

### éœ€è¦è½‰æ›ç‚º kaggle_map.py æ ¼å¼

**è½‰æ›è…³æœ¬ç¤ºä¾‹ï¼š**
```python
import pandas as pd

# è®€å– predict_test.py çš„è¼¸å‡º
df = pd.read_csv('result.csv')

# è½‰æ›æ ¼å¼
def convert_to_kaggle_format(row):
    detections = []
    for det in row['label_list'].split(';'):
        if det:
            class_id, x1, y1, x2, y2, conf = det.split()
            class_name = CLASSES[int(class_id)]
            detections.append([
                class_name, 
                float(conf), 
                float(x1), 
                float(y1), 
                float(x2), 
                float(y2)
            ])
    return str(detections)

df['prediction_list'] = df.apply(convert_to_kaggle_format, axis=1)
df = df[['image_id', 'prediction_list']]
df.to_csv('submission.csv', index=False)
```

---

## ğŸ“ é—œéµæŠ€è¡“é»ç¸½çµ

### 1. è²ªå¿ƒåŒ¹é…ç­–ç•¥ (Greedy Matching)

- æŒ‰confidenceå¾é«˜åˆ°ä½è™•ç†é æ¸¬
- æ¯å€‹çœŸå¯¦æ¡†åªèƒ½åŒ¹é…ä¸€æ¬¡
- é«˜confidenceé æ¸¬å„ªå…ˆæ¶ä½”çœŸå¯¦æ¡†

**å„ªé»ï¼š**
- âœ… ç°¡å–®é«˜æ•ˆ
- âœ… ç¬¦åˆVOCå”è­°

**ç¼ºé»ï¼š**
- âš ï¸ éæœ€å„ªåŒ¹é…ï¼ˆä¸æ˜¯å…¨å±€æœ€å„ªï¼‰
- âš ï¸ å¾ŒçºŒä½confidenceé æ¸¬å¯èƒ½æ‰¾ä¸åˆ°åŒ¹é…

### 2. Precision-Recall æ›²ç·š

**ç‰¹é»ï¼š**
- Recallå–®èª¿éå¢ï¼ˆéš¨è‘—é æ¸¬å¢å¤šï¼‰
- Precisioné€šå¸¸éœ‡ç›ªï¼ˆTP/FPæ¯”ä¾‹è®ŠåŒ–ï¼‰

**å–®èª¿åŒ–çš„æ„ç¾©ï¼š**
- ä½¿ç”¨"å³å´æœ€å¤§å€¼"å¹³æ»‘æ›²ç·š
- æ¶ˆé™¤å±€éƒ¨æ³¢å‹•
- æ¨™æº–åŒ–è©•ä¼°æ–¹æ³•

### 3. VOC2010 vs VOC2007

**VOC2007 (11é»æ’å€¼)ï¼š**
```python
ap = 0
for t in [0, 0.1, 0.2, ..., 1.0]:
    ap += max(precision where recall >= t)
ap /= 11
```

**VOC2010 (æœ¬è…³æœ¬ä½¿ç”¨)ï¼š**
```python
# ä½¿ç”¨æ‰€æœ‰Recallè®ŠåŒ–é»
ap = Î£ (recall[i+1] - recall[i]) Ã— precision[i+1]
```

**å„ªå‹¢ï¼š**
- âœ… æ›´ç²¾ç¢ºï¼ˆä½¿ç”¨æ‰€æœ‰æ•¸æ“šé»ï¼‰
- âœ… ä¸å—å›ºå®šæ’å€¼é»é™åˆ¶

### 4. IoUè¨ˆç®—çš„+1.0

```python
area = (xmax - xmin + 1.0) * (ymax - ymin + 1.0)
```

**åŸå› ï¼š**
- åƒç´ åæ¨™æ˜¯é›¢æ•£çš„
- é‚Šç•Œæ¡†åŒ…å«ç«¯é»
- ç¬¦åˆVOCæ¨™æº–

### 5. æ•¸å€¼ç©©å®šæ€§

```python
precision = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)
```

**ç›®çš„ï¼š** é¿å…é™¤ä»¥0

```python
if not np.isfinite(result):
    result = 0.0
```

**ç›®çš„ï¼š** è™•ç†NaN/Inf

---

## ğŸ” èª¿è©¦æŠ€å·§

### 1. æŸ¥çœ‹å„é¡åˆ¥AP

```python
for i, cls in enumerate(CLASSES):
    ap = aps[i] if i < len(aps) else None
    print(f"{cls}: {ap:.4f}" if ap is not None else f"{cls}: N/A")
```

### 2. æŸ¥çœ‹åŒ¹é…çµæœ

```python
for i, (image_id, score, box) in enumerate(sorted_preds):
    result = "TP" if tp[i] == 1.0 else "FP"
    print(f"Pred {i}: {result}, conf={score:.3f}, img={image_id}")
```

### 3. é©—è­‰IoUè¨ˆç®—

```python
box_a = np.array([10, 10, 50, 50])
box_b = np.array([30, 30, 70, 70])
iou = _bbox_iou(box_a, box_b)
print(f"IoU: {iou:.4f}")
```

---

## ğŸ“Š æ€§èƒ½è€ƒé‡

### æ™‚é–“è¤‡é›œåº¦

**ç¸½é«”ï¼š** O(N Ã— M)
- Nï¼šé æ¸¬æ¡†ç¸½æ•¸
- Mï¼šæ¯å¼µåœ–ç‰‡çš„çœŸå¯¦æ¡†æ•¸é‡ï¼ˆé€šå¸¸å¾ˆå°ï¼‰

**ç“¶é ¸ï¼š** IoUè¨ˆç®—ï¼ˆé›™é‡å¾ªç’°ï¼‰

### ç©ºé–“è¤‡é›œåº¦

**O(N + K)**
- Nï¼šå­˜å„²æ‰€æœ‰é æ¸¬
- Kï¼šå­˜å„²æ‰€æœ‰çœŸå¯¦æ¡†

---

## ğŸ¯ å¯¦éš›ä½¿ç”¨

### æœ¬åœ°è©•ä¼°

```python
import pandas as pd
from kaggle_map import score

# è¼‰å…¥æ•¸æ“š
solution = pd.read_csv('solution.csv')
submission = pd.read_csv('submission.csv')

# è¨ˆç®—mAP
map_score = score(solution, submission, 'id')
print(f"mAP: {map_score:.4f}")
```

### Kaggleæäº¤

1. ä½¿ç”¨ `predict_test.py` ç”Ÿæˆé æ¸¬
2. è½‰æ›ç‚ºKaggleæ ¼å¼
3. ä¸Šå‚³ `submission.csv` åˆ°Kaggle
4. Kaggleä½¿ç”¨ `kaggle_map.py` è‡ªå‹•è©•åˆ†

---

## ğŸ“š åƒè€ƒè³‡æ–™

### VOC Challenge

- **è«–æ–‡ï¼š** "The PASCAL Visual Object Classes Challenge 2010 (VOC2010)"
- **ç¶²ç«™ï¼š** http://host.robots.ox.ac.uk/pascal/VOC/
- **æ¨™æº–ï¼š** IoUé–¾å€¼0.5ï¼Œ11é»æ’å€¼æ”¹é€²ç‰ˆ

### ç›¸é—œæ¦‚å¿µ

- **IoU (Intersection over Union)**ï¼šäº¤ä¸¦æ¯”
- **AP (Average Precision)**ï¼šå¹³å‡ç²¾åº¦
- **mAP (mean Average Precision)**ï¼šå¹³å‡AP
- **TP/FP/FN**ï¼šçœŸé™½/å‡é™½/å‡é™°
- **Precision/Recall**ï¼šç²¾ç¢ºç‡/å¬å›ç‡

---

## âœ… ç¸½çµ

### kaggle_map.py çš„ä½œç”¨

1. âœ… **æ¨™æº–åŒ–è©•ä¼°**ï¼šä½¿ç”¨VOC2010å”è­°
2. âœ… **è‡ªå‹•åŒ–è©•åˆ†**ï¼šKaggleç«¶è³½å¾Œå°ä½¿ç”¨
3. âœ… **éŒ¯èª¤æª¢æ¸¬**ï¼šé©—è­‰æäº¤æ ¼å¼
4. âœ… **å…¬å¹³æ¯”è¼ƒ**ï¼šæ‰€æœ‰åƒè³½è€…ä½¿ç”¨ç›¸åŒè©•ä¼°æ–¹æ³•

### é—œéµç‰¹é»

- **IoUé–¾å€¼**ï¼š0.5
- **åŒ¹é…ç­–ç•¥**ï¼šè²ªå¿ƒåŒ¹é…
- **APè¨ˆç®—**ï¼šVOC2010æ’å€¼æ³•
- **mAP**ï¼š20å€‹é¡åˆ¥APçš„å¹³å‡

### èˆ‡è¨“ç·´çš„é—œè¯

- **è¨“ç·´æ™‚**ï¼šä½¿ç”¨ `src/eval_voc.py` è©•ä¼°mAP
- **æäº¤æ™‚**ï¼šKaggleä½¿ç”¨ `kaggle_map.py` è©•ä¼°
- **å…©è€…æ‡‰è©²ä¸€è‡´**ï¼šç¢ºä¿æœ¬åœ°è©•ä¼°æº–ç¢º

ç†è§£é€™å€‹è…³æœ¬æœ‰åŠ©æ–¼ï¼š
1. âœ… äº†è§£è©•ä¼°æ¨™æº–
2. âœ… èª¿è©¦é æ¸¬çµæœ
3. âœ… å„ªåŒ–æ¨¡å‹æ€§èƒ½
4. âœ… æº–å‚™Kaggleæäº¤

ğŸš€ ç¾åœ¨æ‚¨å¯ä»¥æº–ç¢ºç†è§£æ¨¡å‹æ˜¯å¦‚ä½•è¢«è©•ä¼°çš„ï¼
